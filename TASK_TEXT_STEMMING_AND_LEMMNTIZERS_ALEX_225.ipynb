{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d904851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14609e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_0= ''' All I want is a proper cup of coffee.\n",
    "Made in a proper copper coffee pot.\n",
    "You can believe it or not.\n",
    "But I want a cup of coffee from a proper copper pot.\n",
    "Tin coffee pots or iron coffee pots, they’re not good to me.\n",
    "If I can’t have a proper cup of coffee from a proper copper coffee pot, I’ll just have tea.\n",
    "All I want is a proper cup of coffee.\n",
    "Made in a proper copper coffee pot.\n",
    "You can believe it or not.\n",
    "But I want a cup of coffee from a proper copper pot.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b27cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1='''To sit in solemn silence in a dull, dark dock,\n",
    "In a pestilential prison, with a life-long lock,\n",
    "Awaiting the sensation of a short, sharp shock,\n",
    "From a cheap and chippy chopper on a big black block!\n",
    "To sit in solemn silence in a dull, dark dock,\n",
    "In a pestilential prison, with a life-long lock,\n",
    "Awaiting the sensation of a short, sharp shock,\n",
    "From a cheap and chippy chopper on a big black block!\n",
    "A dull, dark dock, a life-long lock,\n",
    "A short, sharp shock, a big black block!\n",
    "To sit in solemn silence in a pestilential prison,\n",
    "And awaiting the sensation\n",
    "From a cheap and chippy chopper on a big black block!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6d80d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_2=''' Betty Botter bought some butter but, said she, the butter’s bitter.\n",
    "If I put it in my batter, it will make my batter bitter.\n",
    "But a bit of better butter will make my bitter batter better.\n",
    "So she bought some better butter, better than the bitter butter,\n",
    "put it in her bitter batter, made her bitter batter better.\n",
    "So ‘t was better Betty Botter bought some better butter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae0b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_3='''I’m a mother pheasant plucker, I pluck mother pheasants.\n",
    "I’m the most pleasant mother pheasant plucker to ever pluck a mother pheasant.\n",
    "I’m not the pheasant plucker I’m the pheasant plucker’s wife, I’ve been plucking Mother pheasants my whole pheasant plucking life.\n",
    "I’m not the pheasant plucker I’m the pheasant plucker’s mate, I’m only plucking Pheasants ’cause the pheasant plucker’s late.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dac8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_4='''A tree-toad loved a she-toad\n",
    "Who lived up in a tree.\n",
    "He was a two-toed tree-toad,\n",
    "But a three-toed toad was she.\n",
    "The two-toed tree-toad tried to win\n",
    "The three-toed she-toad’s heart,\n",
    "For the two-toed tree-toad loved the ground\n",
    "That the three-toed tree-toad trod.\n",
    "But the two-toed tree-toad tried in vain;\n",
    "He couldn’t please her whim.\n",
    "From her tree-toad bower,\n",
    "With her three-toed power,\n",
    "The she-toad vetoed him.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb3cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Org = pd.DataFrame({'docs' : [doc_0 , doc_1 , doc_2 , doc_3 , doc_4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37aca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_Org.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc21c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I want is a proper cup of coffee.\\nMade i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To sit in solemn silence in a dull, dark dock,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty Botter bought some butter but, said she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m a mother pheasant plucker, I pluck mother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A tree-toad loved a she-toad\\nWho lived up in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs\n",
       "0   All I want is a proper cup of coffee.\\nMade i...\n",
       "1  To sit in solemn silence in a dull, dark dock,...\n",
       "2   Betty Botter bought some butter but, said she...\n",
       "3  I’m a mother pheasant plucker, I pluck mother ...\n",
       "4  A tree-toad loved a she-toad\\nWho lived up in ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eefca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(data , stem = False):\n",
    "    \n",
    "    # Removing htnl tags\n",
    "    html_tag = re.sub(r'<.*?>' , '' , data)\n",
    "    \n",
    "    # Removing special char and --> number are depends upon data\n",
    "    spcl_chr = re.sub(r'[^A-z ]','',html_tag)\n",
    "    \n",
    "    # handling newline char(\\n)\n",
    "    newline_tag = re.sub(r'\\n',' ',spcl_chr)\n",
    "    \n",
    "    # Converting uniform case --> preferble (lower)\n",
    "    sentns = newline_tag.lower()\n",
    "    \n",
    "    # spliting the data\n",
    "    tokens = sentns.split()\n",
    "    \n",
    "    # Removing stopwords\n",
    "    clean_tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    \n",
    "    # stemming or lemmatize\n",
    "    if stem:\n",
    "        doc_list = [SnowballStemmer('english').stem(i) for i in clean_tokens]\n",
    "    else:\n",
    "        doc_list = [WordNetLemmatizer().lemmatize(i) for i in clean_tokens]\n",
    "    \n",
    "    return ' '.join(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6962e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_cleaned_lemmatizer'] = df['docs'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb171e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "      <th>Text_cleaned_lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I want is a proper cup of coffee.\\nMade i...</td>\n",
       "      <td>want proper cup coffeemade proper copper coffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To sit in solemn silence in a dull, dark dock,...</td>\n",
       "      <td>sit solemn silence dull dark dockin pestilenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty Botter bought some butter but, said she...</td>\n",
       "      <td>betty botter bought butter said butter bitteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m a mother pheasant plucker, I pluck mother ...</td>\n",
       "      <td>im mother pheasant plucker pluck mother pheasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A tree-toad loved a she-toad\\nWho lived up in ...</td>\n",
       "      <td>treetoad loved shetoadwho lived treehe twotoed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs  \\\n",
       "0   All I want is a proper cup of coffee.\\nMade i...   \n",
       "1  To sit in solemn silence in a dull, dark dock,...   \n",
       "2   Betty Botter bought some butter but, said she...   \n",
       "3  I’m a mother pheasant plucker, I pluck mother ...   \n",
       "4  A tree-toad loved a she-toad\\nWho lived up in ...   \n",
       "\n",
       "                             Text_cleaned_lemmatizer  \n",
       "0  want proper cup coffeemade proper copper coffe...  \n",
       "1  sit solemn silence dull dark dockin pestilenti...  \n",
       "2  betty botter bought butter said butter bitteri...  \n",
       "3  im mother pheasant plucker pluck mother pheasa...  \n",
       "4  treetoad loved shetoadwho lived treehe twotoed...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd37e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_cleaned_stemmer'] = df['docs'].apply(cleaning_text,stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c194fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "      <th>Text_cleaned_lemmatizer</th>\n",
       "      <th>Text_cleaned_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I want is a proper cup of coffee.\\nMade i...</td>\n",
       "      <td>want proper cup coffeemade proper copper coffe...</td>\n",
       "      <td>want proper cup coffeemad proper copper coffe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To sit in solemn silence in a dull, dark dock,...</td>\n",
       "      <td>sit solemn silence dull dark dockin pestilenti...</td>\n",
       "      <td>sit solemn silenc dull dark dockin pestilenti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty Botter bought some butter but, said she...</td>\n",
       "      <td>betty botter bought butter said butter bitteri...</td>\n",
       "      <td>betti botter bought butter said butter bitteri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m a mother pheasant plucker, I pluck mother ...</td>\n",
       "      <td>im mother pheasant plucker pluck mother pheasa...</td>\n",
       "      <td>im mother pheasant plucker pluck mother pheasa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A tree-toad loved a she-toad\\nWho lived up in ...</td>\n",
       "      <td>treetoad loved shetoadwho lived treehe twotoed...</td>\n",
       "      <td>treetoad love shetoadwho live treeh twoto tree...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docs  \\\n",
       "0   All I want is a proper cup of coffee.\\nMade i...   \n",
       "1  To sit in solemn silence in a dull, dark dock,...   \n",
       "2   Betty Botter bought some butter but, said she...   \n",
       "3  I’m a mother pheasant plucker, I pluck mother ...   \n",
       "4  A tree-toad loved a she-toad\\nWho lived up in ...   \n",
       "\n",
       "                             Text_cleaned_lemmatizer  \\\n",
       "0  want proper cup coffeemade proper copper coffe...   \n",
       "1  sit solemn silence dull dark dockin pestilenti...   \n",
       "2  betty botter bought butter said butter bitteri...   \n",
       "3  im mother pheasant plucker pluck mother pheasa...   \n",
       "4  treetoad loved shetoadwho lived treehe twotoed...   \n",
       "\n",
       "                                Text_cleaned_stemmer  \n",
       "0  want proper cup coffeemad proper copper coffe ...  \n",
       "1  sit solemn silenc dull dark dockin pestilenti ...  \n",
       "2  betti botter bought butter said butter bitteri...  \n",
       "3  im mother pheasant plucker pluck mother pheasa...  \n",
       "4  treetoad love shetoadwho live treeh twoto tree...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c097530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def stem_text(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035d5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "238d80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bs4 import BeautifulSoup  # For HTML tag removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33cd1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_stem(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "    # Remove special characters and keep only alphabets and spaces\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "\n",
    "    # Initialize the Snowball Stemmer for English\n",
    "    stemmer = SnowballStemmer('english')\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Stem each word and join them back into a string\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    cleaned_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35bf9c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betti bought a bit of butter . but the butter betti bought was bitter . so betti bought a better butter , and it was better than the butter betti bought befor .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample text\n",
    "text = \"Betty bought a bit of butter. But the butter Betty bought was bitter. So Betty bought a better butter, and it was better than the butter Betty bought before.\"\n",
    "\n",
    "# Initialize the Snowball Stemmer for English\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Stem each word and join them back into a string\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "stemmed_text = ' '.join(stemmed_words)\n",
    "\n",
    "print(stemmed_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4fdba799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betty bought a bit of butter . But the butter Betty bought wa bitter . So Betty bought a better butter , and it wa better than the butter Betty bought before .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Sample text\n",
    "text = \"Betty bought a bit of butter. But the butter Betty bought was bitter. So Betty bought a better butter, and it was better than the butter Betty bought before.\"\n",
    "\n",
    "# Initialize the WordNet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "# Lemmatize each word and join them back into a string\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "lemmatized_text = ' '.join(lemmatized_words)\n",
    "\n",
    "print(lemmatized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1fd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
